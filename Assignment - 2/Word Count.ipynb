{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JipJznekEFaS"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    with open(r\"/Users/rava/Documents/Neural Networks Assignments/Assignment - 2/input.txt\", \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "\n",
        "    with open(\"output.txt\", \"w\") as output_file:\n",
        "        for line in lines:\n",
        "            words = line.strip().split()\n",
        "            word_count = {}  # Reset the dictionary for each line\n",
        "\n",
        "            for word in words:\n",
        "                word_count[word] = word_count.get(word, 0) + 1\n",
        "\n",
        "            # Print the line\n",
        "            output_file.write(line)\n",
        "\n",
        "            # Print the word count for the current line\n",
        "            for word, count in word_count.items():\n",
        "                output_file.write(f\"{word}: {count}\\n\")\n",
        "\n",
        "            # Empty line for better readability\n",
        "            output_file.write(\"\\n\")\n",
        "\n",
        "        # Print the total word count\n",
        "        output_file.write(\"Word_Count:\\n\")\n",
        "        for word, count in word_count.items():\n",
        "            output_file.write(f\"{word}: {count}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
